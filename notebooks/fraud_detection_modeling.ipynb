{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection - Data Modeling\n",
    "\n",
    "In this notebook, we will build machine learning models to detect fraudulent transactions in the credit card dataset. The goal is to evaluate several models and choose the one with the best performance in identifying fraud, given the highly imbalanced nature of the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load the preprocessed dataset\n",
    "data = pd.read_csv('../data/raw/creditcard.csv')\n",
    "\n",
    "# Split features and labels\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']\n",
    "\n",
    "# Scale the 'Amount' and 'Time' features\n",
    "scaler = StandardScaler()\n",
    "X[['scaled_amount', 'scaled_time']] = scaler.fit_transform(X[['Amount', 'Time']])\n",
    "X = X.drop(['Amount', 'Time'], axis=1)\n",
    "\n",
    "# Handle class imbalance using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>-1.996583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>-1.996583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>-1.996562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>-1.996562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>-1.996541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568625</th>\n",
       "      <td>-0.125056</td>\n",
       "      <td>2.797045</td>\n",
       "      <td>-6.436962</td>\n",
       "      <td>3.250654</td>\n",
       "      <td>-1.673880</td>\n",
       "      <td>-2.737504</td>\n",
       "      <td>-2.301424</td>\n",
       "      <td>0.969237</td>\n",
       "      <td>-1.900690</td>\n",
       "      <td>-4.937166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.647769</td>\n",
       "      <td>0.129735</td>\n",
       "      <td>0.201975</td>\n",
       "      <td>0.005538</td>\n",
       "      <td>-0.168130</td>\n",
       "      <td>0.569294</td>\n",
       "      <td>0.156908</td>\n",
       "      <td>-0.102253</td>\n",
       "      <td>0.051029</td>\n",
       "      <td>1.084762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568626</th>\n",
       "      <td>-3.352917</td>\n",
       "      <td>0.753401</td>\n",
       "      <td>-1.698278</td>\n",
       "      <td>0.863169</td>\n",
       "      <td>-1.186314</td>\n",
       "      <td>-0.406322</td>\n",
       "      <td>-1.652498</td>\n",
       "      <td>0.020940</td>\n",
       "      <td>-0.018209</td>\n",
       "      <td>-2.696694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342796</td>\n",
       "      <td>0.454379</td>\n",
       "      <td>-0.130009</td>\n",
       "      <td>-0.499223</td>\n",
       "      <td>-0.042935</td>\n",
       "      <td>0.987288</td>\n",
       "      <td>-1.389017</td>\n",
       "      <td>0.750979</td>\n",
       "      <td>0.052576</td>\n",
       "      <td>-0.637311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568627</th>\n",
       "      <td>0.341900</td>\n",
       "      <td>1.691419</td>\n",
       "      <td>-1.741040</td>\n",
       "      <td>3.690779</td>\n",
       "      <td>-0.817104</td>\n",
       "      <td>-0.767287</td>\n",
       "      <td>-2.054896</td>\n",
       "      <td>0.551213</td>\n",
       "      <td>-2.026584</td>\n",
       "      <td>-2.605154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285721</td>\n",
       "      <td>-0.473509</td>\n",
       "      <td>0.007435</td>\n",
       "      <td>-0.078866</td>\n",
       "      <td>0.455098</td>\n",
       "      <td>-0.052333</td>\n",
       "      <td>0.542619</td>\n",
       "      <td>0.293170</td>\n",
       "      <td>-0.336907</td>\n",
       "      <td>-1.301187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568628</th>\n",
       "      <td>-1.269532</td>\n",
       "      <td>4.185133</td>\n",
       "      <td>-6.113043</td>\n",
       "      <td>5.037080</td>\n",
       "      <td>1.080631</td>\n",
       "      <td>-2.122858</td>\n",
       "      <td>-1.298991</td>\n",
       "      <td>0.575999</td>\n",
       "      <td>-3.684205</td>\n",
       "      <td>-6.215259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.330215</td>\n",
       "      <td>-0.863163</td>\n",
       "      <td>-0.292751</td>\n",
       "      <td>-0.297741</td>\n",
       "      <td>0.296018</td>\n",
       "      <td>-0.013180</td>\n",
       "      <td>0.780460</td>\n",
       "      <td>0.397597</td>\n",
       "      <td>-0.126700</td>\n",
       "      <td>1.060474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568629</th>\n",
       "      <td>-4.623207</td>\n",
       "      <td>3.077593</td>\n",
       "      <td>-6.235568</td>\n",
       "      <td>2.944704</td>\n",
       "      <td>-1.631924</td>\n",
       "      <td>-1.953885</td>\n",
       "      <td>-3.738838</td>\n",
       "      <td>-0.285921</td>\n",
       "      <td>-0.296130</td>\n",
       "      <td>-4.403317</td>\n",
       "      <td>...</td>\n",
       "      <td>1.545660</td>\n",
       "      <td>0.307303</td>\n",
       "      <td>0.379633</td>\n",
       "      <td>0.733697</td>\n",
       "      <td>-0.535237</td>\n",
       "      <td>-0.009844</td>\n",
       "      <td>-1.623033</td>\n",
       "      <td>1.441260</td>\n",
       "      <td>-0.234667</td>\n",
       "      <td>0.485418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>568630 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0      -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1       1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2      -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3      -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4      -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "568625 -0.125056  2.797045 -6.436962  3.250654 -1.673880 -2.737504 -2.301424   \n",
       "568626 -3.352917  0.753401 -1.698278  0.863169 -1.186314 -0.406322 -1.652498   \n",
       "568627  0.341900  1.691419 -1.741040  3.690779 -0.817104 -0.767287 -2.054896   \n",
       "568628 -1.269532  4.185133 -6.113043  5.037080  1.080631 -2.122858 -1.298991   \n",
       "568629 -4.623207  3.077593 -6.235568  2.944704 -1.631924 -1.953885 -3.738838   \n",
       "\n",
       "              V8        V9       V10  ...       V21       V22       V23  \\\n",
       "0       0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474   \n",
       "1       0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288   \n",
       "2       0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412   \n",
       "3       0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321   \n",
       "4      -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "568625  0.969237 -1.900690 -4.937166  ...  0.647769  0.129735  0.201975   \n",
       "568626  0.020940 -0.018209 -2.696694  ...  0.342796  0.454379 -0.130009   \n",
       "568627  0.551213 -2.026584 -2.605154  ...  0.285721 -0.473509  0.007435   \n",
       "568628  0.575999 -3.684205 -6.215259  ...  0.330215 -0.863163 -0.292751   \n",
       "568629 -0.285921 -0.296130 -4.403317  ...  1.545660  0.307303  0.379633   \n",
       "\n",
       "             V24       V25       V26       V27       V28  scaled_amount  \\\n",
       "0       0.066928  0.128539 -0.189115  0.133558 -0.021053       0.244964   \n",
       "1      -0.339846  0.167170  0.125895 -0.008983  0.014724      -0.342475   \n",
       "2      -0.689281 -0.327642 -0.139097 -0.055353 -0.059752       1.160686   \n",
       "3      -1.175575  0.647376 -0.221929  0.062723  0.061458       0.140534   \n",
       "4       0.141267 -0.206010  0.502292  0.219422  0.215153      -0.073403   \n",
       "...          ...       ...       ...       ...       ...            ...   \n",
       "568625  0.005538 -0.168130  0.569294  0.156908 -0.102253       0.051029   \n",
       "568626 -0.499223 -0.042935  0.987288 -1.389017  0.750979       0.052576   \n",
       "568627 -0.078866  0.455098 -0.052333  0.542619  0.293170      -0.336907   \n",
       "568628 -0.297741  0.296018 -0.013180  0.780460  0.397597      -0.126700   \n",
       "568629  0.733697 -0.535237 -0.009844 -1.623033  1.441260      -0.234667   \n",
       "\n",
       "        scaled_time  \n",
       "0         -1.996583  \n",
       "1         -1.996583  \n",
       "2         -1.996562  \n",
       "3         -1.996562  \n",
       "4         -1.996541  \n",
       "...             ...  \n",
       "568625     1.084762  \n",
       "568626    -0.637311  \n",
       "568627    -1.301187  \n",
       "568628     1.060474  \n",
       "568629     0.485418  \n",
       "\n",
       "[568630 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "568625    1\n",
       "568626    1\n",
       "568627    1\n",
       "568628    1\n",
       "568629    1\n",
       "Name: Class, Length: 568630, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/10 01:31:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95     56750\n",
      "           1       0.97      0.92      0.95     56976\n",
      "\n",
      "    accuracy                           0.95    113726\n",
      "   macro avg       0.95      0.95      0.95    113726\n",
      "weighted avg       0.95      0.95      0.95    113726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Split the resampled data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Train Logistic Regression model\n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = log_reg.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    clf_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    # Log model parameters\n",
    "    mlflow.log_param(\"model_type\", \"LogisticRegression\")\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.log_metric(\"precision\", clf_report['1']['precision'])\n",
    "    mlflow.log_metric(\"recall\", clf_report['1']['recall'])\n",
    "    mlflow.log_metric(\"f1_score\", clf_report['1']['f1-score'])\n",
    "    \n",
    "    # Log the model itself\n",
    "    mlflow.sklearn.log_model(log_reg, \"logistic_regression_model\")\n",
    "\n",
    "    # Print the classification report\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # End MLflow run\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/10 01:27:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56750\n",
      "           1       1.00      1.00      1.00     56976\n",
      "\n",
      "    accuracy                           1.00    113726\n",
      "   macro avg       1.00      1.00      1.00    113726\n",
      "weighted avg       1.00      1.00      1.00    113726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Start an MLflow run for Random Forest\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Train Random Forest model\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "    clf_report_rf = classification_report(y_test, y_pred_rf, output_dict=True)\n",
    "\n",
    "    # Log model parameters\n",
    "    mlflow.log_param(\"model_type\", \"RandomForest\")\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", acc_rf)\n",
    "    mlflow.log_metric(\"precision\", clf_report_rf['1']['precision'])\n",
    "    mlflow.log_metric(\"recall\", clf_report_rf['1']['recall'])\n",
    "    mlflow.log_metric(\"f1_score\", clf_report_rf['1']['f1-score'])\n",
    "    \n",
    "    # Log the model itself\n",
    "    mlflow.sklearn.log_model(rf_model, \"random_forest_model\")\n",
    "\n",
    "    # Print the classification report\n",
    "    print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "    # End MLflow run\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/10 01:27:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56750\n",
      "           1       1.00      1.00      1.00     56976\n",
      "\n",
      "    accuracy                           1.00    113726\n",
      "   macro avg       1.00      1.00      1.00    113726\n",
      "weighted avg       1.00      1.00      1.00    113726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Start an MLflow run for XGBoost\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Train XGBoost model\n",
    "    xgb_model = xgb.XGBClassifier(random_state=42)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_xgb = xgb_model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    acc_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "    clf_report_xgb = classification_report(y_test, y_pred_xgb, output_dict=True)\n",
    "\n",
    "    # Log model parameters\n",
    "    mlflow.log_param(\"model_type\", \"XGBoost\")\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", acc_xgb)\n",
    "    mlflow.log_metric(\"precision\", clf_report_xgb['1']['precision'])\n",
    "    mlflow.log_metric(\"recall\", clf_report_xgb['1']['recall'])\n",
    "    mlflow.log_metric(\"f1_score\", clf_report_xgb['1']['f1-score'])\n",
    "    \n",
    "    # Log the model itself\n",
    "    mlflow.sklearn.log_model(xgb_model, \"xgboost_model\")\n",
    "\n",
    "    # Print the classification report\n",
    "    print(classification_report(y_test, y_pred_xgb))\n",
    "\n",
    "    # End MLflow run\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
